{
  "cells": [
    {
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "import os\nimport numpy as np\nimport cv2\nfrom tqdm import tqdm\nfrom sklearn.model_selection import train_test_split",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "trusted": true,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "TRAIN_IMAGE_DIR = '../input/train/images/'\nTRAIN_MASK_DIR = '../input/train/masks/'\nTEST_IMAGE_DIR = '../input/test/images/'",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "915c294275675cc567792bd0ef862ab90c7bf7d5",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "train_fns = os.listdir(TRAIN_IMAGE_DIR)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "503e4bc26d8f55ca3e58846cf5b2c6f5a0418b0d",
        "collapsed": true
      },
      "cell_type": "markdown",
      "source": "## U-net approach"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "409465e1aaa90273238e0cf7a1d9cd79416a63c0",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "from keras.models import Model\nfrom keras.layers import Input, Conv2D\nfrom keras.layers import BatchNormalization\nfrom keras.layers import Dropout, MaxPooling2D\nfrom keras.layers import Activation, concatenate\nfrom keras.layers import Conv2DTranspose\n\nfrom keras.optimizers import Adam\nfrom keras import losses\n\nfrom keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\nfrom keras.preprocessing.image import ImageDataGenerator\n\nfrom sklearn.model_selection import train_test_split",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "161d608119d1b5d42cff43b68f1436e23acbbc39",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "X = [np.array(cv2.resize(cv2.imread(TRAIN_IMAGE_DIR + p, cv2.IMREAD_GRAYSCALE), (128, 128)), \n              dtype=np.uint8) for p in tqdm(train_fns)]\nX = np.array(X)/255\nX = np.expand_dims(X,axis=3)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "31f00e5ea2fd7a319bff5be4666124e2fc822c4f",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "y = [np.array(cv2.resize(cv2.imread(TRAIN_MASK_DIR + p, cv2.IMREAD_GRAYSCALE), \n                         (128, 128)), dtype = np.uint8) for p in tqdm(train_fns)]\ny = np.array(y) / 255\ny = np.expand_dims(y, axis = 3)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "02cefe1bc6f8b184448c146a753086bc81044cfd",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.25)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "collapsed": true,
        "_uuid": "a19288227dc9fd6e92c2317997633f41a37ff5f9"
      },
      "cell_type": "code",
      "source": "def conv_block(neurons, block_input, dropout=None):\n    conv1 = Conv2D(neurons, (3,3), padding='same')(block_input)\n    conv1 = Activation('relu')(conv1)\n    conv1 = BatchNormalization()(conv1)\n    if dropout is not None:\n        conv1 = Dropout(dropout)(conv1)\n    conv2 = Conv2D(neurons, (3,3), padding='same')(conv1)\n    conv2 = Activation('relu')(conv2)\n    conv2 = BatchNormalization()(conv2)\n    if dropout is not None:\n        conv2 = Dropout(dropout)(conv2)\n    pool = MaxPooling2D((2,2))(conv2)\n    return pool, conv2  # returns the block output and the shortcut to use in the uppooling blocks\n\ndef middle_block(neurons, block_input, dropout=None):\n    conv1 = Conv2D(neurons, (3,3), padding='same')(block_input)\n    conv1 = Activation('relu')(conv1)\n    conv1 = BatchNormalization()(conv1)\n    if dropout is not None:\n        conv1 = Dropout(dropout)(conv1)\n    conv2 = Conv2D(neurons, (3,3), padding='same')(conv1)\n    conv2 = Activation('relu')(conv2)\n    conv2 = BatchNormalization()(conv2)\n    if dropout is not None:\n        conv2 = Dropout(dropout)(conv2)\n    \n    return conv2\n\ndef deconv_block(neurons, block_input, shortcut, dropout=None):\n    deconv = Conv2DTranspose(neurons, (3, 3), strides=(2, 2), padding=\"same\")(block_input)\n    uconv = concatenate([deconv, shortcut])\n    uconv = Conv2D(neurons, (3, 3), padding=\"same\")(uconv)\n    uconv = Activation('relu')(uconv)\n    uconv = BatchNormalization()(uconv)\n    if dropout is not None:\n        uconv = Dropout(dropout)(uconv)\n    uconv = Conv2D(neurons, (3, 3), padding=\"same\")(uconv)\n    uconv = Activation('relu')(uconv)\n    uconv = BatchNormalization()(uconv)\n    if dropout is not None:\n        uconv = Dropout(dropout)(uconv)\n        \n    return uconv\n    \ndef build_model(start_neurons=8, dropout=None):\n    \n    input_layer = Input((128, 128, 1))\n    \n    # 128 -> 64\n    conv1, shortcut1 = conv_block(start_neurons, input_layer, dropout)\n\n    # 64 -> 32\n    conv2, shortcut2 = conv_block(start_neurons * 2, conv1, dropout)\n    \n    # 32 -> 16\n    conv3, shortcut3 = conv_block(start_neurons * 4, conv2, dropout)\n    \n    # 16 -> 8\n    conv4, shortcut4 = conv_block(start_neurons * 8, conv3, dropout)\n    \n    # Middle\n    convm = middle_block(start_neurons * 16, conv4, dropout)\n    \n    # 8 -> 16\n    deconv4 = deconv_block(start_neurons * 8, convm, shortcut4, dropout)\n    \n    # 16 -> 32\n    deconv3 = deconv_block(start_neurons * 4, deconv4, shortcut3, dropout)\n    \n    # 32 -> 64\n    deconv2 = deconv_block(start_neurons * 2, deconv3, shortcut2, dropout)\n    \n    # 64 -> 128\n    deconv1 = deconv_block(start_neurons, deconv2, shortcut1, dropout)\n    \n    #uconv1 = Dropout(0.5)(uconv1)\n    output_layer = Conv2D(1, (1,1), padding=\"same\", activation=\"sigmoid\")(deconv1)\n    \n    model = Model(input_layer, output_layer)\n    return model",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "897ab32c8a1a33ea8918c716f0b77ac34a8e0014",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "model = build_model(start_neurons=8)\nearly_stopping = EarlyStopping(patience=50, verbose=1)\nreduce_lr = ReduceLROnPlateau(monitor='val_loss',\n                               factor=0.1,\n                               patience=4,\n                               verbose=1,\n                               min_delta=1e-4)\nmodel_checkpoint = ModelCheckpoint('weights1.h5', \n                                    save_weights_only=True, \n                                    save_best_only=True)\ncallbacks = [early_stopping, reduce_lr, model_checkpoint]\noptimizer = Adam(lr=0.01)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "7ea25d59b5b559548e8f9ba592aa47b73da12fb8",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "model.compile(loss=losses.binary_crossentropy,\n              optimizer=Adam(),\n              metrics = ['accuracy'])",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "597847e0bb7d430e6b9687e3b883634acaa29d4b",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "history = model.fit(X_train, y_train, \n          batch_size=32, epochs=200,\n          validation_data = [X_val, y_val],\n          callbacks = callbacks)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "59a509cc5371e30de5f76fb22e59d5c507830bc8",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "model.load_weights('weights1.h5')\nmodel.evaluate(X_val, y_val, verbose=1)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "4d2895cafa82e8921236568689ecb7c218d2ef46",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "import matplotlib.pyplot as plt\nplt.plot(history.history['acc'])\nplt.plot(history.history['val_acc'])\nplt.plot(np.argmax(history.history['val_acc']), np.argmax(history.history['acc']), \n               marker=\"x\", color=\"r\", label=\"best model\")\nplt.xlabel(\"Epochs\")\nplt.title('model accuracy')\nplt.xlabel('epochs')\nplt.ylabel('accuracy')\nplt.ylim([0.8,1.0])\nplt.legend(['train', 'test'], loc= 'upper left')",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "e437a60014ead59d651435145b6c9c91ff3fb548",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "data_gen_args = dict(horizontal_flip = True,\n                     vertical_flip = True)\nimage_datagen = ImageDataGenerator(**data_gen_args)\nmask_datagen = ImageDataGenerator(**data_gen_args)\n\nseed = 2018\nbs = 32\n\nimage_generator = image_datagen.flow(X_train, \n                                     seed = seed, batch_size = bs, shuffle = True)\nmask_generator = image_datagen.flow(y_train, \n                                     seed = seed, batch_size = bs, shuffle = True)\n\ntrain_generator = zip(image_generator, mask_generator)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "63f28e2b1a2f87650b38fc5f2ceb6108658a9d29",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "model_checkpoint = ModelCheckpoint('weights2.h5', \n                                    save_weights_only=True, \n                                    save_best_only=True)\ncallbacks = [early_stopping, reduce_lr, model_checkpoint]\n\nresults = model.fit_generator(train_generator, \n                             steps_per_epoch=(len(X_train) // bs),\n                             epochs = 200, callbacks = callbacks,\n                             validation_data=(X_val, y_val))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "f502d2a9eb4a7879fa044bd416efdaebc52b8b92",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "model.load_weights('weights2.h5')\nmodel.evaluate(X_val, y_val, verbose=1)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "e71bfb876b24f3e5dcb5c027d805a2fb8cd45857",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "import matplotlib.pyplot as plt\nplt.plot(history.history['acc'])\nplt.plot(history.history['val_acc'])\nplt.plot(np.argmax(history.history['val_acc']), np.argmax(history.history['acc']), \n               marker=\"x\", color=\"r\", label=\"best model\")\nplt.xlabel(\"Epochs\")\nplt.title('model accuracy')\nplt.xlabel('epochs')\nplt.ylabel('accuracy')\nplt.ylim([0.8,1.0])\nplt.legend(['train', 'test'], loc= 'upper left')",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "f320e9487c16757a5b7166315ad70f237f46cdf9",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "preds_train = model.predict(X_train, verbose=1)\npreds_val = model.predict(X_val, verbose = 1)\n\npreds_train_t = (preds_train > 0.5).astype(np.uint8)\npreds_val_t = (preds_train > 0.5).astype(np.uint8)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "71741c7a825d994dd7ba091f0b55015977a8636d",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "def plot_sample(X, y, preds, binary_preds, ix= None):\n    if ix is None:\n        ix = random.randint(0, len(X))\n    \n    has_mask = y[ix].max() > 0\n    \n    fig, ax = plt.subplots(1, 4, figsize=(20,20))\n    ax[0].imshow(X[ix,...,0], cmap='seismic')\n    if has_mask:\n        ax[0].contour(y[ix].squeeze(), colors='k', levels=[0.5])\n    ax[0].set_title('Seismic')\n    \n    ax[1].imshow(y[ix].squeeze())\n    ax[1].set_title('Salt')\n    \n    ax[2].imshow(preds[ix].squeeze(), vmin=0, vmax=1)\n    if has_mask:\n        ax[2].contour(y[ix].squeeze(), colors='k', levels=[0.5])\n    ax[2].set_title('Salt Predicted')\n    \n    ax[3].imshow(binary_preds[ix].squeeze(), vmin=0, vmax=1)\n    if has_mask:\n        ax[3].contour(y[ix].squeeze(), colors='k', levels=[0.5])\n    \n    ax[3].set_title('Salt Predicted Binary')",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "f7676a7ce3bc5f94682746f5105b9d0afb74e56c",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "plot_sample(X_train, y_train, preds_train, preds_train_t, ix = 100)",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.4",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}